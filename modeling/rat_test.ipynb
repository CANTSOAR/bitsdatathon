{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dipalshah/Desktop/bitsdatathon/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name ProsusAI/finbert. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from rat import RAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dipalshah/Desktop/bitsdatathon/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "rat_model = RAT(input_dim=22, embed_dim=32, num_heads=2, num_layers=2, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dipalshah/Desktop/bitsdatathon/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.001976, Val Loss: 1.032158\n",
      "Epoch 5/100, Train Loss: 0.947513, Val Loss: 1.048166\n",
      "Epoch 10/100, Train Loss: 0.949447, Val Loss: 1.030656\n",
      "Epoch 15/100, Train Loss: 0.946700, Val Loss: 1.095391\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9701862335205078"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data (assuming this returns DataFrame with all features)\n",
    "data = rat_model.get_data(\"AAPL\", start_date=\"2000-01-01\", end_date=\"2025-03-02\")\n",
    "\n",
    "# Separate stock price/volume from other features\n",
    "stock_features = data[['Close', 'Volume']].values  # Price and volume\n",
    "other_features = data.drop(['Close', 'Volume'], axis=1).values.astype(dtype=\"float32\")  # Other features\n",
    "\n",
    "# Format data for training\n",
    "input_length = 30  # 30 days of history\n",
    "output_length = 15  # predict 15 days ahead\n",
    "X, y = rat_model.format_data_separate(stock_features, other_features, input_length, output_length)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "rat_model.train_model(epochs, batch_size, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Compute the loss (just for showing val_loss, adjust if necessary)\u001b[39;00m\n\u001b[32m     22\u001b[39m criterion = nn.MSELoss()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m predicted_values = \u001b[43mrat_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Reshaping for transformer\u001b[39;00m\n\u001b[32m     24\u001b[39m transformed_predicted_values = close_price_scaler.transform(predicted_values)\n\u001b[32m     25\u001b[39m loss = criterion(transformed_predicted_values, y[:, :, \u001b[32m0\u001b[39m].reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m))  \u001b[38;5;66;03m# Ensure y is in the correct shape\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "N = 5  # Number of periods to plot\n",
    "\n",
    "num_samples = X.shape[0]\n",
    "if N > num_samples:\n",
    "    N = num_samples  # Ensure N is within range\n",
    "\n",
    "# Extract the last N periods of input and target for close price\n",
    "last_X = X[-N:, :, 0].cpu().numpy()  # Shape: (N, input_length)\n",
    "last_y = rat_model.predict(X)[0]\n",
    "print(last_y.shape)\n",
    "\n",
    "#[-N:, :, 0].cpu().numpy()  # Shape: (N, output_length)\n",
    "\n",
    "# Inverse transform close price (since we scaled it)\n",
    "close_price_scaler = rat_model.stock_scalers[0]\n",
    "last_X = close_price_scaler.inverse_transform(last_X)\n",
    "\n",
    "# Compute the loss (just for showing val_loss, adjust if necessary)\n",
    "criterion = nn.MSELoss()\n",
    "predicted_values = rat_model.predict(X)[0, :, 0].reshape(-1, 1)  # Reshaping for transformer\n",
    "transformed_predicted_values = close_price_scaler.transform(predicted_values)\n",
    "loss = criterion(transformed_predicted_values, y[:, :, 0].reshape(-1, 1))  # Ensure y is in the correct shape\n",
    "val_loss = loss.item()\n",
    "avg_val_loss = val_loss / len(y)\n",
    "print(avg_val_loss)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(N):\n",
    "    # Plot input (last_X)\n",
    "    input_range = range(i * (last_X.shape[1]), (i + 1) * last_X.shape[1])\n",
    "    plt.plot(input_range, last_X[i], label=f\"Input {i+1} (History)\", linestyle=\"dotted\", alpha=0.6)\n",
    "    \n",
    "    # Plot target (last_y)\n",
    "    output_range = range(input_range[-1], input_range[-1] + last_y.shape[1])\n",
    "    plt.plot(output_range, last_y[i], label=f\"Target {i+1} (Prediction)\", linestyle=\"solid\")\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Close Price\")\n",
    "plt.title(f\"Last {N} Periods of Stock Close Price\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
